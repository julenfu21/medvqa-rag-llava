{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQA Model Result Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set-Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import Dataset, disable_progress_bars, load_dataset\n",
    "\n",
    "from utils.enums import VQAStrategyType\n",
    "from utils.notebook_helpers import display_base64_image, display_formatted_section\n",
    "from utils.string_formatting_helpers import format_vqa_strategy_name\n",
    "from visual_qa_model import VisualQAModel\n",
    "from visual_qa_strategies.rag_q_vqa_strategy import RagQVQAStrategy\n",
    "from visual_qa_strategies.zero_shot_vqa_strategy import ZeroShotVQAStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Detect Google Colab Form Annotation Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "function code_toggle(id) {\n",
       "    var cells = document.querySelectorAll(\".jp-CodeCell\");\n",
       "    for (var cell of cells) {\n",
       "        if (cell.querySelector(\"#\" + id) !== null) {\n",
       "            var div = cell.querySelector(\".jp-InputArea\");\n",
       "            if (div.style.display === \"none\") {\n",
       "                div.style.display = \"block\";\n",
       "            } else {\n",
       "                div.style.display = \"none\";\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext ipyform\n",
    "%form_config --auto-detect 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_qa_pair_by_id(\n",
    "    model: VisualQAModel,\n",
    "    dataset: Dataset,\n",
    "    id: int,\n",
    "    image_width: Optional[int] = None,\n",
    "    image_height: Optional[int] = None\n",
    ") -> None:\n",
    "    # Obtain row by index\n",
    "    filtered_dataset = dataset.filter(lambda row: row['index'] == id)\n",
    "    if len(filtered_dataset) == 0:\n",
    "        raise ValueError(f\"No row found with index {id}\")\n",
    "    else:\n",
    "        row = filtered_dataset[0]\n",
    "\n",
    "    # Display row id\n",
    "    display_formatted_section(\n",
    "        section_name=\"ID\",\n",
    "        section_style=\"margin: 20px 0;\",\n",
    "        section_content=row['index']\n",
    "    )\n",
    "\n",
    "    # Display question\n",
    "    display_formatted_section(\n",
    "        section_name=\"Question\",\n",
    "        section_style=\"margin-bottom: 20px;\",\n",
    "        section_content=row['question']\n",
    "    )\n",
    "\n",
    "    # Display context image\n",
    "    display_formatted_section(\n",
    "        section_name=\"Context Image\",\n",
    "        section_style=\"margin-bottom: 20px;\",\n",
    "        section_content=\"\"\n",
    "    )\n",
    "    display_base64_image(\n",
    "        base64_image=row['image'],\n",
    "        width=image_width,\n",
    "        height=image_height\n",
    "    )\n",
    "\n",
    "    # Predict answer\n",
    "    predicted_option = model.generate_answer_from_row(\n",
    "        row=row,\n",
    "        possible_options=['A', 'B', 'C', 'D']\n",
    "    )\n",
    "\n",
    "    # Display possible answers marking both the gold and the predicted option\n",
    "    formatted_options = []\n",
    "    possible_options = ['A', 'B', 'C', 'D']\n",
    "    for option in possible_options:\n",
    "        if option == row['correct_option']:\n",
    "            formatted_options.append(f\"<p style='color: rgb(0, 255, 0);'><b>{option}) {row[option]}</b>\")\n",
    "        elif option == predicted_option:\n",
    "            formatted_options.append(f\"<p style='color: rgb(255, 0, 0);'><b>{option}) {row[option]}</b>\")\n",
    "        else:\n",
    "            formatted_options.append(f\"<p>{option}) {row[option]}\")\n",
    "    answer = \"<br><br>\" + \"<br>\".join(formatted_options)\n",
    "\n",
    "    display_formatted_section(\n",
    "        section_name=\"Possible Answers\",\n",
    "        section_style=\"margin-top: 30px;\",\n",
    "        section_content=answer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_result_from_json(\n",
    "    evaluation_results_folder: Path,\n",
    "    question_id: int,\n",
    "    vqa_strategy_name: str\n",
    ") -> str:\n",
    "    evaluation_results_filename = f'spain_english_{vqa_strategy_name}_evaluation.json'\n",
    "    evaluation_results_path = evaluation_results_folder / evaluation_results_filename\n",
    "    with open(evaluation_results_path, mode='r', encoding='utf-8') as evaluation_file:\n",
    "        evaluation_data = json.load(evaluation_file)\n",
    "    \n",
    "    return evaluation_data['predictions'][question_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluate VQA Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path(\"../data/WorldMedQA-V\")\n",
    "MODEL_NAME = \"llava\"\n",
    "COUNTRY = \"spain\"\n",
    "FILE_TYPE = \"english\"\n",
    "RESULTS_DIR = Path('../evaluation_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'image', 'question', 'A', 'B', 'C', 'D', 'answer', 'correct_option', 'split'],\n",
       "    num_rows: 125\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dataset file path\n",
    "dataset_filename = f\"{COUNTRY}_{FILE_TYPE}_processed.tsv\"\n",
    "data_filepath = str(DATASET_DIR / dataset_filename)\n",
    "\n",
    "# Load dataset\n",
    "world_med_qa_v_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[data_filepath],\n",
    "    sep=\"\\t\",\n",
    ")[\"train\"]\n",
    "world_med_qa_v_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Zero-Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading Zero-Shot Strategy ...\n",
      "+ Zero-Shot Strategy loaded.\n",
      "- Loading Llava Model ...\n",
      "+ Llava Model Loaded.\n"
     ]
    }
   ],
   "source": [
    "llava_model = VisualQAModel(\n",
    "    visual_qa_strategy=ZeroShotVQAStrategy(),\n",
    "    model_name=MODEL_NAME,\n",
    "    country=COUNTRY,\n",
    "    file_type=FILE_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model (spain_english subset) ...: 100%|██████████| 5/5 [06:24<00:00, 76.97s/it]\n"
     ]
    }
   ],
   "source": [
    "llava_model.evaluate(\n",
    "    dataset=world_med_qa_v_dataset.take(5),\n",
    "    save_path=RESULTS_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Specific Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = Path('../data/WikiMed/indexed_db')\n",
    "INDEX_NAME = \"Wikimed+S-PubMedBert-MS-MARCO-FullTexts\"\n",
    "EMBEDDING_MODEL_NAME = \"pritamdeka/S-PubMedBert-MS-MARCO\"\n",
    "RELEVANT_DOCS_COUNT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. RAG Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading RAG Q Strategy ...\n",
      "\t- Loading Embeddings ...\n",
      "\t+ Embeddings Loaded.\n",
      "\t- Loading Index ...\n",
      "\t+ Index Loaded.\n",
      "\t- Loading Retriever ...\n",
      "\t+ Retriever Loaded.\n",
      "+ RAG Q Strategy loaded.\n",
      "- Loading Llava Model ...\n",
      "+ Llava Model Loaded.\n"
     ]
    }
   ],
   "source": [
    "llava_model.visual_qa_strategy = RagQVQAStrategy(\n",
    "    index_dir=INDEX_DIR,\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    relevant_docs_count=RELEVANT_DOCS_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model (spain_english subset) ...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model (spain_english subset) ...: 100%|██████████| 5/5 [18:23<00:00, 220.77s/it]\n"
     ]
    }
   ],
   "source": [
    "llava_model.evaluate(\n",
    "    dataset=world_med_qa_v_dataset.take(5),\n",
    "    save_path=RESULTS_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. RAG Q+As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3. RAG IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4. RAG DB, RERANKER, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VQA Approaches Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Specific Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path(\"../data/WorldMedQA-V\")\n",
    "MODEL_NAME = \"llava\"\n",
    "COUNTRY = \"spain\"\n",
    "FILE_TYPE = \"english\"\n",
    "RESULTS_DIR = Path('../evaluation_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RAG Q Specific Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = Path('../data/WikiMed/indexed_db')\n",
    "INDEX_NAME = \"Wikimed+S-PubMedBert-MS-MARCO-FullTexts\"\n",
    "EMBEDDING_MODEL_NAME = \"pritamdeka/S-PubMedBert-MS-MARCO\"\n",
    "RELEVANT_DOCS_COUNT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Possible VQA Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading Zero-Shot Strategy ...\n",
      "+ Zero-Shot Strategy loaded.\n",
      "- Loading RAG Q Strategy ...\n",
      "\t- Loading Embeddings ...\n",
      "\t+ Embeddings Loaded.\n",
      "\t- Loading Index ...\n",
      "\t+ Index Loaded.\n",
      "\t- Loading Retriever ...\n",
      "\t+ Retriever Loaded.\n",
      "+ RAG Q Strategy loaded.\n"
     ]
    }
   ],
   "source": [
    "vqa_strategies = {\n",
    "    VQAStrategyType.ZERO_SHOT: ZeroShotVQAStrategy(),\n",
    "    VQAStrategyType.RAG_Q: RagQVQAStrategy(\n",
    "        index_dir=INDEX_DIR,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        relevant_docs_count=RELEVANT_DOCS_COUNT\n",
    "    ),\n",
    "    VQAStrategyType.RAG_Q_AS: None,\n",
    "    VQAStrategyType.RAG_IMG: None,\n",
    "    VQAStrategyType.RAG_DB_RERANKER: None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'image', 'question', 'A', 'B', 'C', 'D', 'answer', 'correct_option', 'split'],\n",
       "    num_rows: 125\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dataset file path\n",
    "dataset_filename = f\"{COUNTRY}_{FILE_TYPE}_processed.tsv\"\n",
    "data_filepath = str(DATASET_DIR / dataset_filename)\n",
    "\n",
    "# Load dataset\n",
    "world_med_qa_v_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[data_filepath],\n",
    "    sep=\"\\t\",\n",
    ")[\"train\"]\n",
    "world_med_qa_v_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid progress bar when applying filter to dataset\n",
    "disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a48b6829b0f437b8f86305a09e27a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FormWidget(children=(VBox(children=(HTML(value=''), HTML(value='<h2>Interactive VQA Model Exploration Form</h2…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Interactive VQA Model Exploration Form\n",
    "vqa_strategy_type = 'Zero-Shot' # @param [\"Zero-Shot\", \"RAG Q\", \"RAG Q+As\", \"RAG IMG\", \"RAG DB-Reranker\"]\n",
    "question_id = 1 # @param {\"type\":\"integer\"}\n",
    "image_width = 600 # @param {\"type\":\"integer\"}\n",
    "action = 'Fetch from JSON' # @param [\"Execute Model\", Fetch from JSON]\n",
    "\n",
    "\n",
    "if action == \"Execute Model\":\n",
    "    visualize_qa_pair_by_id(\n",
    "        model=VisualQAModel(\n",
    "            visual_qa_strategy=vqa_strategies[vqa_strategy_type],\n",
    "            model_name=MODEL_NAME,\n",
    "            country=COUNTRY,\n",
    "            file_type=FILE_TYPE\n",
    "        ),\n",
    "        dataset=world_med_qa_v_dataset,\n",
    "        id=question_id,\n",
    "        image_width=image_width\n",
    "    )\n",
    "elif action == \"Fetch from JSON\":\n",
    "    result = fetch_result_from_json(\n",
    "        evaluation_results_folder=RESULTS_DIR,\n",
    "        question_id=question_id,\n",
    "        vqa_strategy_name=format_vqa_strategy_name(strategy_name=vqa_strategy_type)\n",
    "    )\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
